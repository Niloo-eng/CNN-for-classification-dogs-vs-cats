{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification dogs vs cats.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-YDAw_NUnVI"
      },
      "source": [
        "# load requirments library\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline \n",
        "\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#our libraries\n",
        "#from train import train_model\n",
        "#from model_utils import *\n",
        "#from predict_utils import *\n",
        "#from vis_utils import *\n",
        "\n",
        "# some initial setup\n",
        "np.set_printoptions(precision = 2)\n",
        "use_gpu = torch.cuda.is_available()\n",
        "np.random.seed(1234)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbj8jiox48fS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2341c672-7c0d-4fa5-cd1a-f2a5f1ab37d6"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DATA_DIR = \"/content/gdrive/My Drive/data/dataset\"\n",
        "\n",
        "sz = 224\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_72KPXs_7ilB"
      },
      "source": [
        "##%%%%dataset\n",
        "DATA_DIR = \"/content/gdrive/My Drive/data/dataset\"\n",
        "\n",
        "#!ls\"/content/drive/My Drive/ColabNotebooks/data\"\n",
        "#DATA_DIR = \"https://drive.google.com/drive/folders/136QdGHviw2R2yt3S4dE7COICoyEDhLeI?usp=sharing\"\n",
        "#os.listdir(DATA_DIR)\n",
        "###from google.colab import files\n",
        "###uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XErb6CN4ffm_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9bf81eb-a02f-49ed-d948-5f6447b6c9dd"
      },
      "source": [
        "\n",
        "os.listdir(DATA_DIR)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valid', 'train', 'Test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfgquL_sbOo4"
      },
      "source": [
        "trn_dir = f'{DATA_DIR}train'\n",
        "valid_dir = f'{DATA_DIR}valid'\n",
        "\n",
        "#os.listdir(trn_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm0nu29ebv7k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fbab4b63-ab92-47c8-85e8-97a015cee25d"
      },
      "source": [
        "trn_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/data/datasettrain'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkI7YWMWeoJV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "cf4eb3ac-3986-4fd2-da39-a9af3a4522d6"
      },
      "source": [
        "os.listdir(trn_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-60a033a733bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/data/datasettrain'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaPygy27k-wI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXPysRmde0O2"
      },
      "source": [
        "#show image\n",
        "trn_fnames = glob.glob(f'{trn_dir}/*/*.jpg')\n",
        "trn_fnames[:5]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvB_mfVkk_tB"
      },
      "source": [
        "#dir(glob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4pXFaFElnlB"
      },
      "source": [
        "#plot image\n",
        "img = plt.imread(trn_fnames[1])\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElkYuR47qGGC"
      },
      "source": [
        "##datasets\n",
        "train_ds = datasets.ImageFolder(trn_dir)\n",
        "train_ds.classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9qevRq4qpFX"
      },
      "source": [
        "#%%for indexing classes to 0 & 1\n",
        "train_ds.class_to_idx\n",
        "##for watching path\n",
        "train_ds.root \n",
        "# for seeing images with classes\n",
        "train_ds.imgs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30yBELJKsEH4"
      },
      "source": [
        "##%%Transformations; data loader object uses theses transformations when loading data.  \n",
        "tfms = transforms.Compose([\n",
        "                           transforms.Resize((sz,sz)), #PIL Image\n",
        "                           transforms.ToTensor(),  #change to matrix\n",
        "                           transforms.Normalize([0.485,0.456, 0.406], [0.229, 0.224,0.225])    \n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(trn_dir,transform = tfms)\n",
        "valid_ds = datasets.ImageFolder(val_dir,transform = tfms)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkjHfd_e5xam"
      },
      "source": [
        "##dataloaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds,batch_size=batch_size, shuffle = True, num_workers = 8)\n",
        "valid_dl = torch.utils.data.DataLoader(valid_ds,batch_size=batch_size, shuffle = True, num_workers = 8)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyFPiMX0-YRg"
      },
      "source": [
        "##iterator\n",
        "inputs, targets = next(iter(train_dl))\n",
        "out = torchvision.utils.make_grid(inputs, padding=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wotAFPu_AQE"
      },
      "source": [
        "##ModelCNN\n",
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.conv2d(3, 16, kernel_size=5, padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)        \n",
        "    )\n",
        "\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.conv2d(16, 32, kernel_size = 5, padding=2),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Linear(56 * 56 * 32, 2)\n",
        "\n",
        "def forward(self, x):\n",
        "  out = self.conv1(x)\n",
        "  out = self.conv2(out)\n",
        "  out = out.view(out.size(0), -1) ###for changing 4 to 2 tensor\n",
        "  out = self.fc(out)\n",
        "  return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw68KDiWGj39"
      },
      "source": [
        "#now it's time to create model\n",
        "model = SimpleCNN()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNPXblkBHARB"
      },
      "source": [
        "##lossfunction and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parametes(), lr=0.002, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLnapPEbIdah"
      },
      "source": [
        "##train\n",
        "num_epochs = 10\n",
        "losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, targets) in enumerate(train_dl):\n",
        "        inputs = to_var(inputs)\n",
        "        targets = to_var(targets)\n",
        "        \n",
        "        # forwad pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # loss\n",
        "        loss = criterion(outputs, targets)\n",
        "        losses += [loss.data[0]]\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        # report\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print('Epoch [%2d/%2d], Step [%3d/%3d], Loss: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i + 1, len(train_ds) // batch_size, loss.data[0]))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByVk6niq3Mw7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}